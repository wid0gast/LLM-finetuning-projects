{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import openai\n",
    "# from openai.embeddings_utils import get_embedding\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/fine-food-reviews/Reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "df = df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.Text[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Score = df.Score - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns.difference(['Text', 'Score']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.6)\n",
    "val_df = df.drop(train_df.index).sample(frac=0.25)\n",
    "test_df = df.drop(train_df.index).drop(val_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 191182.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([9.135e+03, 7.230e+02, 9.800e+01, 2.700e+01, 7.000e+00, 6.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 2.000e+00]),\n",
       " array([  10. ,  160.3,  310.6,  460.9,  611.2,  761.5,  911.8, 1062.1,\n",
       "        1212.4, 1362.7, 1513. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = []\n",
    "for text in tqdm(df.Text):\n",
    "    lens.append(len(text.split()))\n",
    "\n",
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2031, 4149, 2195, 1997, 1996, 8995, 3012, 27141, 3899, 2833, 3688, 1998, 2031, 2179, 2068, 2035, 2000, 2022, 1997, 2204, 3737, 1012, 1996, 4031, 3504, 2062, 2066, 1037, 20717, 2084, 1037, 13995, 6240, 1998, 2009, 14747, 2488, 1012, 2026, 18604, 2003, 10346, 6799, 2100, 1998, 2016, 9120, 2015, 2023, 4031, 2488, 2084, 2087, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(sample, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6000 [00:00<?, ?it/s]c:\\Users\\Shaz\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 6000/6000 [00:11<00:00, 506.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "\n",
    "for text in tqdm(train_df.Text):\n",
    "    tok = tokenizer.encode_plus(text, add_special_tokens=True, max_length=256, pad_to_max_length=True, truncation=True, return_attention_mask=True, return_tensors='pt')\n",
    "    train_input_ids.append(tok['input_ids'])\n",
    "    train_attention_masks.append(tok['attention_mask'])\n",
    "\n",
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 514.59it/s]\n"
     ]
    }
   ],
   "source": [
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "\n",
    "for text in tqdm(val_df.Text):\n",
    "    tok = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, pad_to_max_length=True, truncation=True, return_attention_mask=True, return_tensors='pt')\n",
    "    val_input_ids.append(tok['input_ids'])\n",
    "    val_attention_masks.append(tok['attention_mask'])\n",
    "\n",
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(val_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:05<00:00, 585.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_input_ids = []\n",
    "test_attention_masks = []\n",
    "\n",
    "for text in tqdm(test_df.Text):\n",
    "    tok = tokenizer.encode_plus(text, add_special_tokens=True, max_length=512, pad_to_max_length=True, truncation=True, return_attention_mask=True, return_tensors='pt')\n",
    "    test_input_ids.append(tok['input_ids'])\n",
    "    test_attention_masks.append(tok['attention_mask'])\n",
    "\n",
    "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
    "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
    "test_labels = torch.tensor(test_df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU: ', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "if device.type == 'cuda':\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shaz\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-6\n",
    "optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [02:50<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.26\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:17<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.62\n",
      "  Validation Loss: 1.10\n",
      "\n",
      "======== Epoch 2 / 5 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [02:50<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 1.02\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:17<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.64\n",
      "  Validation Loss: 0.91\n",
      "\n",
      "======== Epoch 3 / 5 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [02:50<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.90\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:18<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.69\n",
      "  Validation Loss: 0.83\n",
      "\n",
      "======== Epoch 4 / 5 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [02:51<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.83\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:18<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.72\n",
      "  Validation Loss: 0.77\n",
      "\n",
      "======== Epoch 5 / 5 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [02:57<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.77\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:18<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.74\n",
      "  Validation Loss: 0.74\n",
      "\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "\n",
    "    print()\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print()\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "    # training_stats.append(\n",
    "    #     {\n",
    "    #         'epoch': epoch_i + 1,\n",
    "    #         'Training Loss': avg_train_loss,\n",
    "    #         'Valid. Loss': avg_val_loss,\n",
    "    #         'Valid. Accur.': avg_val_accuracy,\n",
    "    #         'Training Time': training_time,\n",
    "    #         'Validation Time': validation_time\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
